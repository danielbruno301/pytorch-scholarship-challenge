{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 8 - Transfer Learning (Exercises).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Z8m7tkARwLqo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning\n",
        "\n",
        "In this notebook, you'll learn how to use pre-trained networks to solved challenging problems in computer vision. Specifically, you'll use networks trained on [ImageNet](http://www.image-net.org/) [available from torchvision](http://pytorch.org/docs/0.3.0/torchvision/models.html). \n",
        "\n",
        "ImageNet is a massive dataset with over 1 million labeled images in 1000 categories. It's used to train deep neural networks using an architecture called convolutional layers. I'm not going to get into the details of convolutional networks here, but if you want to learn more about them, please [watch this](https://www.youtube.com/watch?v=2-Ol7ZB0MmU).\n",
        "\n",
        "Once trained, these models work astonishingly well as feature detectors for images they weren't trained on. Using a pre-trained network on images not in the training set is called transfer learning. Here we'll use transfer learning to train a network that can classify our cat and dog photos with near perfect accuracy.\n",
        "\n",
        "With `torchvision.models` you can download these pre-trained networks and use them in your applications. We'll include `models` in our imports now."
      ]
    },
    {
      "metadata": {
        "id": "_qUVQks1xA05",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B0LrS3lUwLqr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JYpOprfxwLqz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Most of the pretrained models require the input to be 224x224 images. Also, we'll need to match the normalization used when the models were trained. Each color channel was normalized separately, the means are `[0.485, 0.456, 0.406]` and the standard deviations are `[0.229, 0.224, 0.225]`."
      ]
    },
    {
      "metadata": {
        "id": "DBcMMwT7x1oX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "697b15cc-fec6-4595-c0dd-894c54cdf270"
      },
      "cell_type": "code",
      "source": [
        "!wget -c https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip;\n",
        "!unzip -qq Cat_Dog_data.zip;"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-19 00:04:49--  https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.111.77\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.111.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 580495262 (554M) [application/zip]\n",
            "Saving to: ‘Cat_Dog_data.zip’\n",
            "\n",
            "Cat_Dog_data.zip    100%[===================>] 553.60M  77.3MB/s    in 7.4s    \n",
            "\n",
            "2018-12-19 00:04:56 (74.9 MB/s) - ‘Cat_Dog_data.zip’ saved [580495262/580495262]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FEcc0cDHwLq1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = 'Cat_Dog_data'\n",
        "\n",
        "# TODO: Define transforms for the training data and testing data\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "# Pass transforms in here, then run the next cell to see how the transforms look\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-qxsaVGUwLq4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can load in a model such as [DenseNet](http://pytorch.org/docs/0.3.0/torchvision/models.html#id5). Let's print out the model architecture so we can see what's going on."
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "hr23AlajwLq6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8605
        },
        "outputId": "1d5f8083-155a-4141-93c4-f1bd3f5aa0bb"
      },
      "cell_type": "code",
      "source": [
        "model = models.densenet121(pretrained=True)\n",
        "model"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  nn.init.kaiming_normal(m.weight.data)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.torch/models/densenet121-a639ec97.pth\n",
            "100%|██████████| 32342954/32342954 [00:02<00:00, 12730967.02it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseNet(\n",
              "  (features): Sequential(\n",
              "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu0): ReLU(inplace)\n",
              "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (denseblock1): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition1): _Transition(\n",
              "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock2): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition2): _Transition(\n",
              "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock3): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer17): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer18): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer19): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer20): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer21): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer22): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer23): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer24): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition3): _Transition(\n",
              "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock4): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "SsRiqvmZwLq-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This model is built out of two main parts, the features and the classifier. The features part is a stack of convolutional layers and overall works as a feature detector that can be fed into a classifier. The classifier part is a single fully-connected layer `(classifier): Linear(in_features=1024, out_features=1000)`. This layer was trained on the ImageNet dataset, so it won't work for our specific problem. That means we need to replace the classifier, but the features will work perfectly on their own. In general, I think about pre-trained networks as amazingly good feature detectors that can be used as the input for simple feed-forward classifiers."
      ]
    },
    {
      "metadata": {
        "id": "fio1UtC0wLq-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "from collections import OrderedDict\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                          ('fc1', nn.Linear(1024, 500)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('fc2', nn.Linear(500, 2)),\n",
        "                          ('output', nn.LogSoftmax(dim=1))\n",
        "                          ]))\n",
        "    \n",
        "model.classifier = classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qf3p7NcjwLrD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "With our model built, we need to train the classifier. However, now we're using a **really deep** neural network. If you try to train this on a CPU like normal, it will take a long, long time. Instead, we're going to use the GPU to do the calculations. The linear algebra computations are done in parallel on the GPU leading to 100x increased training speeds. It's also possible to train on multiple GPUs, further decreasing training time.\n",
        "\n",
        "PyTorch, along with pretty much every other deep learning framework, uses [CUDA](https://developer.nvidia.com/cuda-zone) to efficiently compute the forward and backwards passes on the GPU. In PyTorch, you move your model parameters and other tensors to the GPU memory using `model.to('cuda')`. You can move them back from the GPU with `model.to('cpu')` which you'll commonly do when you need to operate on the network output outside of PyTorch. As a demonstration of the increased speed, I'll compare how long it takes to perform a forward and backward pass with and without a GPU."
      ]
    },
    {
      "metadata": {
        "id": "Ti9ke-hcwLrF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OFKLGw_o2XVa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "80f4a204-829c-4200-9782-8c3d58c7ee9e"
      },
      "cell_type": "code",
      "source": [
        "!pip install Pillow==4.0.0"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.6MB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.46)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.3.0\n",
            "    Uninstalling Pillow-5.3.0:\n",
            "      Successfully uninstalled Pillow-5.3.0\n",
            "Successfully installed Pillow-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YybYmq6VwLrK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b15484a3-14d5-46d5-8eb9-52171dd014da"
      },
      "cell_type": "code",
      "source": [
        "for device in ['cpu', 'cuda']:\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "    # Only train the classifier parameters, feature parameters are frozen\n",
        "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for ii, (inputs, labels) in enumerate(trainloader):\n",
        "\n",
        "        # Move input and label tensors to the GPU\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        outputs = model.forward(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if ii==3:\n",
        "            break\n",
        "        \n",
        "    print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device = cpu; Time per batch: 7.252 seconds\n",
            "Device = cuda; Time per batch: 0.020 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lv9Z7XbdwLrP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can write device agnostic code which will automatically use CUDA if it's enabled like so:\n",
        "```python\n",
        "# at beginning of the script\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "...\n",
        "\n",
        "# then whenever you get a new Tensor or Module\n",
        "# this won't copy if they are already on the desired device\n",
        "input = data.to(device)\n",
        "model = MyModule(...).to(device)\n",
        "```\n",
        "\n",
        "From here, I'll let you finish training the model. The process is the same as before except now your model is much more powerful. You should get better than 95% accuracy easily.\n",
        "\n",
        ">**Exercise:** Train a pretrained models to classify the cat and dog images. Continue with the DenseNet model, or try ResNet, it's also a good model to try out first. Make sure you are only training the classifier and the parameters for the features part are frozen."
      ]
    },
    {
      "metadata": {
        "id": "fgszTWBG8E4T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## TODO: Use a pretrained model to classify the cat and dog images\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2KwOPDxQ8PjX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jrUvBAHx8hWS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get a pre-trained model\n",
        "model = models.densenet121(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XnTzx7u78S0n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the Classifier for the cat-dog problem\n",
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "from collections import OrderedDict\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                          ('fc1', nn.Linear(1024, 500)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('fc2', nn.Linear(500, 2)),\n",
        "                          ('output', nn.LogSoftmax(dim=1))\n",
        "                          ]))\n",
        "    \n",
        "model.classifier = classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CS0YUpda8zdT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.NLLLoss()\n",
        "# Only train the classifier parameters, feature parameters are frozen\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Irzh0mD19EOl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the data set\n",
        "data_dir = 'Cat_Dog_data'\n",
        "# Define transforms for the training data and testing data\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "# Pass transforms in here, then run the next cell to see how the transforms look\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eG4tCrmCwLrR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1207
        },
        "outputId": "e1e9df15-81dc-4740-a7f8-80c43a2af497"
      },
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "\n",
        "step = 0\n",
        "print_every = 5\n",
        "\n",
        "train_losses, test_losses = [], []\n",
        "running_loss = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for images, labels in trainloader:\n",
        "        step += 1\n",
        "        \n",
        "        # Move input and label tensors to the GPU\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        log_probs = model(images)\n",
        "        loss = criterion(log_probs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if step % print_every == 0:\n",
        "            test_loss = 0\n",
        "            accuracy = 0\n",
        "            with torch.no_grad():\n",
        "                model.eval()\n",
        "\n",
        "            for images, labels in testloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                log_probs = model(images)\n",
        "                test_loss += criterion(log_probs, labels)\n",
        "\n",
        "                # Calculate the accuracy\n",
        "                probs = torch.exp(log_probs)\n",
        "                _, top_class = probs.topk(1, dim=1)\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "            model.train()\n",
        "            train_losses.append(running_loss/len(trainloader))\n",
        "            test_losses.append(test_loss/len(testloader))\n",
        "\n",
        "            print('Epoch: {}'.format(epoch+1),\n",
        "              'Training Loss: {:.3f}'.format(running_loss/len(trainloader)),\n",
        "              'Test Loss: {:.3f}'.format(test_loss/len(testloader)),\n",
        "              'Test Accuracy: {:.3f}%'.format(100*accuracy/len(testloader)))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 Training Loss: 0.003 Test Loss: 0.170 Test Accuracy: 92.852%\n",
            "Epoch: 1 Training Loss: 0.006 Test Loss: 0.096 Test Accuracy: 96.016%\n",
            "Epoch: 1 Training Loss: 0.008 Test Loss: 0.062 Test Accuracy: 97.461%\n",
            "Epoch: 1 Training Loss: 0.010 Test Loss: 0.055 Test Accuracy: 97.891%\n",
            "Epoch: 1 Training Loss: 0.012 Test Loss: 0.055 Test Accuracy: 98.008%\n",
            "Epoch: 1 Training Loss: 0.014 Test Loss: 0.055 Test Accuracy: 97.891%\n",
            "Epoch: 1 Training Loss: 0.016 Test Loss: 0.056 Test Accuracy: 97.852%\n",
            "Epoch: 1 Training Loss: 0.018 Test Loss: 0.058 Test Accuracy: 97.734%\n",
            "Epoch: 1 Training Loss: 0.021 Test Loss: 0.059 Test Accuracy: 97.695%\n",
            "Epoch: 1 Training Loss: 0.023 Test Loss: 0.057 Test Accuracy: 97.891%\n",
            "Epoch: 1 Training Loss: 0.025 Test Loss: 0.054 Test Accuracy: 98.008%\n",
            "Epoch: 1 Training Loss: 0.028 Test Loss: 0.054 Test Accuracy: 97.930%\n",
            "Epoch: 1 Training Loss: 0.031 Test Loss: 0.054 Test Accuracy: 98.047%\n",
            "Epoch: 1 Training Loss: 0.033 Test Loss: 0.053 Test Accuracy: 98.086%\n",
            "Epoch: 1 Training Loss: 0.036 Test Loss: 0.053 Test Accuracy: 98.008%\n",
            "Epoch: 1 Training Loss: 0.038 Test Loss: 0.053 Test Accuracy: 98.125%\n",
            "Epoch: 1 Training Loss: 0.040 Test Loss: 0.055 Test Accuracy: 97.930%\n",
            "Epoch: 1 Training Loss: 0.042 Test Loss: 0.058 Test Accuracy: 97.773%\n",
            "Epoch: 1 Training Loss: 0.044 Test Loss: 0.056 Test Accuracy: 97.734%\n",
            "Epoch: 1 Training Loss: 0.047 Test Loss: 0.053 Test Accuracy: 98.203%\n",
            "Epoch: 1 Training Loss: 0.049 Test Loss: 0.055 Test Accuracy: 97.891%\n",
            "Epoch: 1 Training Loss: 0.051 Test Loss: 0.054 Test Accuracy: 98.008%\n",
            "Epoch: 1 Training Loss: 0.053 Test Loss: 0.055 Test Accuracy: 98.008%\n",
            "Epoch: 1 Training Loss: 0.055 Test Loss: 0.054 Test Accuracy: 98.047%\n",
            "Epoch: 1 Training Loss: 0.057 Test Loss: 0.053 Test Accuracy: 98.047%\n",
            "Epoch: 1 Training Loss: 0.060 Test Loss: 0.052 Test Accuracy: 98.164%\n",
            "Epoch: 1 Training Loss: 0.062 Test Loss: 0.053 Test Accuracy: 98.008%\n",
            "Epoch: 1 Training Loss: 0.063 Test Loss: 0.055 Test Accuracy: 97.891%\n",
            "Epoch: 1 Training Loss: 0.065 Test Loss: 0.053 Test Accuracy: 97.930%\n",
            "Epoch: 1 Training Loss: 0.067 Test Loss: 0.054 Test Accuracy: 97.852%\n",
            "Epoch: 1 Training Loss: 0.069 Test Loss: 0.052 Test Accuracy: 98.086%\n",
            "Epoch: 1 Training Loss: 0.072 Test Loss: 0.056 Test Accuracy: 97.773%\n",
            "Epoch: 1 Training Loss: 0.073 Test Loss: 0.055 Test Accuracy: 97.812%\n",
            "Epoch: 1 Training Loss: 0.075 Test Loss: 0.051 Test Accuracy: 98.242%\n",
            "Epoch: 1 Training Loss: 0.078 Test Loss: 0.050 Test Accuracy: 98.281%\n",
            "Epoch: 1 Training Loss: 0.080 Test Loss: 0.050 Test Accuracy: 98.320%\n",
            "Epoch: 1 Training Loss: 0.083 Test Loss: 0.050 Test Accuracy: 98.320%\n",
            "Epoch: 1 Training Loss: 0.084 Test Loss: 0.050 Test Accuracy: 98.242%\n",
            "Epoch: 1 Training Loss: 0.086 Test Loss: 0.052 Test Accuracy: 98.164%\n",
            "Epoch: 1 Training Loss: 0.088 Test Loss: 0.050 Test Accuracy: 98.281%\n",
            "Epoch: 1 Training Loss: 0.090 Test Loss: 0.049 Test Accuracy: 98.281%\n",
            "Epoch: 1 Training Loss: 0.092 Test Loss: 0.049 Test Accuracy: 98.359%\n",
            "Epoch: 1 Training Loss: 0.094 Test Loss: 0.050 Test Accuracy: 98.281%\n",
            "Epoch: 1 Training Loss: 0.096 Test Loss: 0.049 Test Accuracy: 98.320%\n",
            "Epoch: 1 Training Loss: 0.098 Test Loss: 0.051 Test Accuracy: 98.086%\n",
            "Epoch: 1 Training Loss: 0.101 Test Loss: 0.050 Test Accuracy: 98.242%\n",
            "Epoch: 1 Training Loss: 0.103 Test Loss: 0.051 Test Accuracy: 98.125%\n",
            "Epoch: 1 Training Loss: 0.105 Test Loss: 0.050 Test Accuracy: 98.047%\n",
            "Epoch: 1 Training Loss: 0.108 Test Loss: 0.049 Test Accuracy: 98.203%\n",
            "Epoch: 1 Training Loss: 0.109 Test Loss: 0.050 Test Accuracy: 98.086%\n",
            "Epoch: 1 Training Loss: 0.112 Test Loss: 0.052 Test Accuracy: 97.930%\n",
            "Epoch: 1 Training Loss: 0.114 Test Loss: 0.052 Test Accuracy: 97.891%\n",
            "Epoch: 1 Training Loss: 0.116 Test Loss: 0.051 Test Accuracy: 98.008%\n",
            "Epoch: 1 Training Loss: 0.119 Test Loss: 0.049 Test Accuracy: 98.320%\n",
            "Epoch: 1 Training Loss: 0.121 Test Loss: 0.049 Test Accuracy: 98.281%\n",
            "Epoch: 1 Training Loss: 0.123 Test Loss: 0.048 Test Accuracy: 98.281%\n",
            "Epoch: 1 Training Loss: 0.126 Test Loss: 0.053 Test Accuracy: 97.852%\n",
            "Epoch: 1 Training Loss: 0.128 Test Loss: 0.056 Test Accuracy: 97.891%\n",
            "Epoch: 1 Training Loss: 0.131 Test Loss: 0.052 Test Accuracy: 97.930%\n",
            "Epoch: 1 Training Loss: 0.134 Test Loss: 0.048 Test Accuracy: 98.359%\n",
            "Epoch: 1 Training Loss: 0.136 Test Loss: 0.050 Test Accuracy: 98.164%\n",
            "Epoch: 1 Training Loss: 0.137 Test Loss: 0.050 Test Accuracy: 98.203%\n",
            "Epoch: 1 Training Loss: 0.140 Test Loss: 0.049 Test Accuracy: 98.320%\n",
            "Epoch: 1 Training Loss: 0.142 Test Loss: 0.049 Test Accuracy: 98.359%\n",
            "Epoch: 1 Training Loss: 0.144 Test Loss: 0.050 Test Accuracy: 98.203%\n",
            "Epoch: 1 Training Loss: 0.146 Test Loss: 0.049 Test Accuracy: 98.281%\n",
            "Epoch: 1 Training Loss: 0.148 Test Loss: 0.049 Test Accuracy: 98.281%\n",
            "Epoch: 1 Training Loss: 0.150 Test Loss: 0.049 Test Accuracy: 98.359%\n",
            "Epoch: 1 Training Loss: 0.152 Test Loss: 0.048 Test Accuracy: 98.359%\n",
            "Epoch: 1 Training Loss: 0.154 Test Loss: 0.048 Test Accuracy: 98.281%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S-1iuNix9Z52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "f42fc9f2-0ae8-439b-d5c0-eb10edaf7b1c"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "# plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(test_losses, label='Validation Loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('Model with Transfer Learning')\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAu8AAAINCAYAAACOD5HYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nED5CknchhBBCCCF8xP8HhMu4+Ao1I/gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f44a619c630>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 375,
              "height": 262
            }
          }
        }
      ]
    }
  ]
}